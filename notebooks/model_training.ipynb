{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a4643f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (800, 16)\n",
      "Test set shape: (200, 16)\n",
      "\n",
      "--- Training Logistic Regression (Baseline) ---\n",
      "Logistic Regression - Test Set Performance:\n",
      "Accuracy: 0.9100\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85        64\n",
      "           1       0.92      0.95      0.93       136\n",
      "\n",
      "    accuracy                           0.91       200\n",
      "   macro avg       0.90      0.89      0.89       200\n",
      "weighted avg       0.91      0.91      0.91       200\n",
      "\n",
      "\n",
      "--- Training XGBoost Classifier (Challenger) ---\n",
      "XGBoost Classifier - Test Set Performance:\n",
      "Accuracy: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        64\n",
      "           1       1.00      1.00      1.00       136\n",
      "\n",
      "    accuracy                           1.00       200\n",
      "   macro avg       1.00      1.00      1.00       200\n",
      "weighted avg       1.00      1.00      1.00       200\n",
      "\n",
      "\n",
      "--- Best model (XGBoost) saved to ../model/model.pkl ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Smart Lead AI\\venv\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:10:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# --- 1. Load Processed Data ---\n",
    "# (PATH CORRECTION): We're in 'notebooks/', so we go up ('../') \n",
    "# and into 'data/'. I'm also using your exact filename.\n",
    "data = pd.read_csv('../data/lead_data_processed.csv')\n",
    "\n",
    "# --- 2. Define Features (X) and Target (y) ---\n",
    "# 'converted' is our target variable (the thing we want to predict)\n",
    "# All other columns are our features\n",
    "X = data.drop('converted', axis=1) \n",
    "y = data['converted']\n",
    "\n",
    "# --- 3. Split Data ---\n",
    "# We use 80% for training and 20% for testing.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "\n",
    "# --- 4. Train Baseline Model: Logistic Regression ---\n",
    "print(\"\\n--- Training Logistic Regression (Baseline) ---\")\n",
    "log_model = LogisticRegression(max_iter=1000) # Increase max_iter for convergence\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_log = log_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Logistic Regression - Test Set Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_log):.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_log))\n",
    "\n",
    "\n",
    "# --- 5. Train Challenger Model: XGBoost ---\n",
    "print(\"\\n--- Training XGBoost Classifier (Challenger) ---\")\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"XGBoost Classifier - Test Set Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "\n",
    "# --- 6. Save the Best Model ---\n",
    "# (PATH CORRECTION): We're in 'notebooks/', so we go up ('../')\n",
    "# and into 'model/' to save the final model file.\n",
    "\n",
    "# We'll assume XGBoost is better, as it usually is for this type of data.\n",
    "# If your Logistic Regression report was better, change 'xgb_model' to 'log_model'.\n",
    "model_to_save = xgb_model \n",
    "model_path = '../model/model.pkl'\n",
    "\n",
    "with open(model_path, 'wb') as file:\n",
    "    pickle.dump(model_to_save, file)\n",
    "\n",
    "print(f\"\\n--- Best model (XGBoost) saved to {model_path} ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
